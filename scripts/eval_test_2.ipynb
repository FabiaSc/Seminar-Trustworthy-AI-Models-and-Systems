{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b0d370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ONE-CELL: build prompts for ONLY your generated images ====================\n",
    "# >>>>>> EDIT THESE (use ABSOLUTE paths) <<<<<<\n",
    "COCO_JSON    = \"/abs/path/to/scripts/utils/captions_val2014.json\"\n",
    "REAL_DIR     = \"/home/group-3/tests_L/MixDQ/scripts/utils/captions_val2014.json\"                      # reference images\n",
    "FP16_DIR     = \"/home/group-3/tests_L/MixDQ/logs/sdxl_fp_eval_big/generated_images\"\n",
    "MIXDQ_DIR    = \"/home/group-3/tests_L/MixDQ/logs/sdxl_mixdq_eval_images_big\"\n",
    "OUT_FP16_TXT = \"/home/group-3/tests_L/MixDQ/scripts/utils/prompts_fp16.txt\"\n",
    "OUT_MIXD_TXT = \"/home/group-3/tests_L/MixDQ/scripts/utils/prompts_mixdq.txt\"\n",
    "OUT_FP16_CSV = \"/home/group-3/tests_L/MixDQ/scripts/utils/prompts_fp16.csv\"\n",
    "OUT_MIXD_CSV = \"/home/group-3/tests_L/MixDQ/scripts/utils/prompts_mixdq.csv\"\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "import os, re, json, csv, glob, pathlib\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "def _abs(p): return os.path.abspath(os.path.expanduser(p))\n",
    "def list_images_recursive(root, exts=(\".png\",\".jpg\",\".jpeg\",\".bmp\",\".webp\")) -> List[str]:\n",
    "    root = _abs(root)\n",
    "    return [p for p in glob.iglob(os.path.join(root, \"**\", \"*\"), recursive=True)\n",
    "            if os.path.isfile(p) and p.lower().endswith(exts)]\n",
    "\n",
    "def natural_key(s: str):\n",
    "    import re\n",
    "    b = os.path.basename(s)\n",
    "    return [int(t) if t.isdigit() else t.lower() for t in re.split(r\"(\\d+)\", b)]\n",
    "\n",
    "def load_coco_maps(coco_json: str):\n",
    "    with open(_abs(coco_json), \"r\", encoding=\"utf-8\") as f:\n",
    "        coco = json.load(f)\n",
    "    id2fname = {im[\"id\"]: im[\"file_name\"] for im in coco[\"images\"]}\n",
    "    # use the FIRST caption per image_id for determinism (you can change this)\n",
    "    id2cap: Dict[int, str] = {}\n",
    "    for ann in coco[\"annotations\"]:\n",
    "        if ann[\"image_id\"] not in id2cap:\n",
    "            id2cap[ann[\"image_id\"]] = ann[\"caption\"].strip()\n",
    "    return id2fname, id2cap\n",
    "\n",
    "def find_coco_id_from_name(name: str, id2fname: Dict[int, str]):\n",
    "    # try to extract a 12-digit COCO id anywhere in the filename\n",
    "    m = re.search(r\"(?<!\\d)(\\d{12})(?!\\d)\", name)\n",
    "    if m:\n",
    "        iid = int(m.group(1))\n",
    "        if iid in id2fname:\n",
    "            return iid, \"12digit\"\n",
    "    return None, None\n",
    "\n",
    "def build_prompts_for_folder(gen_dir: str, id2fname: Dict[int,str], id2cap: Dict[int,str],\n",
    "                             out_txt: str, out_csv: str):\n",
    "    files = sorted(list_images_recursive(gen_dir), key=natural_key)\n",
    "    matched_prompts: List[str] = []\n",
    "    rows = []\n",
    "    n_matched = 0\n",
    "    for p in files:\n",
    "        base = os.path.basename(p)\n",
    "        iid, how = find_coco_id_from_name(base, id2fname)\n",
    "        if iid is not None and iid in id2cap:\n",
    "            cap = id2cap[iid]\n",
    "            matched_prompts.append(cap)\n",
    "            rows.append({\"filename\": base, \"image_id\": iid, \"coco_file_name\": id2fname[iid],\n",
    "                         \"prompt\": cap, \"match_method\": how})\n",
    "            n_matched += 1\n",
    "        else:\n",
    "            # unmatched -> leave placeholder so line count still equals #images\n",
    "            cap = \"a photo\"\n",
    "            matched_prompts.append(cap)\n",
    "            rows.append({\"filename\": base, \"image_id\": \"\", \"coco_file_name\": \"\",\n",
    "                         \"prompt\": cap, \"match_method\": \"UNMATCHED\"})\n",
    "    # write outputs\n",
    "    with open(_abs(out_txt), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(matched_prompts))\n",
    "    with open(_abs(out_csv), \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=[\"filename\",\"image_id\",\"coco_file_name\",\"prompt\",\"match_method\"])\n",
    "        w.writeheader(); w.writerows(rows)\n",
    "    print(f\"{gen_dir}: {n_matched}/{len(files)} matched to COCO captions\")\n",
    "    print(f\"  -> prompts: {out_txt}\")\n",
    "    print(f\"  -> mapping: {out_csv}\")\n",
    "    if n_matched < len(files):\n",
    "        print(\"  NOTE: Some files didnâ€™t contain a 12-digit COCO id; see mapping CSV (match_method=UNMATCHED).\")\n",
    "\n",
    "# ---- run ---------------------------------------------------------------------\n",
    "id2fname, id2cap = load_coco_maps(COCO_JSON)\n",
    "build_prompts_for_folder(GEN_DIR_FP16, id2fname, id2cap, OUT_FP16_TXT, OUT_FP16_CSV)\n",
    "build_prompts_for_folder(GEN_DIR_MIXD, id2fname, id2cap, OUT_MIXD_TXT, OUT_MIXD_CSV)\n",
    "# ==============================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dc19108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Found files  real=0 | fp16=1024 | mixdq=1024\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "One of the folders has 0 readable images. Use ABSOLUTE paths; nested trees are OK.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 179\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound files  real=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(real_files)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | fp16=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(fp16_files)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | mixdq=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(mixd_files)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(real_files) == \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fp16_files) == \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mixd_files) == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mOne of the folders has 0 readable images. Use ABSOLUTE paths; nested trees are OK.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    181\u001b[39m \u001b[38;5;66;03m# Build per-folder prompts\u001b[39;00m\n\u001b[32m    182\u001b[39m id2fname, id2cap = load_coco_maps(COCO_JSON)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: One of the folders has 0 readable images. Use ABSOLUTE paths; nested trees are OK."
     ]
    }
   ],
   "source": [
    "# === ONE-CELL: build prompts for your 1024 imgs + FID + CLIPScore + RI@1 ======\n",
    "# >>>>>> EDIT THESE (absolute paths) <<<<<<\n",
    "COCO_JSON    = \"/abs/path/to/scripts/utils/captions_val2014.json\"\n",
    "REAL_DIR     = \"/home/group-3/tests_L/MixDQ/scripts/utils/captions_val2014.json\"                      # reference images\n",
    "FP16_DIR     = \"/home/group-3/tests_L/MixDQ/logs/sdxl_fp_eval_big/generated_images\"\n",
    "MIXDQ_DIR    = \"/home/group-3/tests_L/MixDQ/logs/sdxl_mixdq_eval_images_big\"\n",
    "OUT_FP16_TXT = \"/home/group-3/tests_L/MixDQ/scripts/utils/prompts_fp16.txt\"\n",
    "OUT_MIXD_TXT = \"/home/group-3/tests_L/MixDQ/scripts/utils/prompts_mixdq.txt\"\n",
    "OUT_FP16_CSV = \"/home/group-3/tests_L/MixDQ/scripts/utils/prompts_fp16.csv\"\n",
    "OUT_MIXD_CSV = \"/home/group-3/tests_L/MixDQ/scripts/utils/prompts_mixdq.csv\"\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "import os, re, json, glob, csv, tempfile, shutil, pathlib\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "import torch, torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Clean-FID\n",
    "from cleanfid import fid\n",
    "\n",
    "# Try open_clip; fallback to HuggingFace transformers CLIP\n",
    "class ClipBackend:\n",
    "    def __init__(self, device=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "        self.device = device\n",
    "        self.name = None\n",
    "        try:\n",
    "            import open_clip\n",
    "            self.oc = open_clip\n",
    "            self.model, _, self.preprocess = open_clip.create_model_and_transforms(\n",
    "                \"ViT-L-14-336\", pretrained=\"openai\", device=device\n",
    "            )\n",
    "            self.tokenizer = open_clip.get_tokenizer(\"ViT-L-14-336\")\n",
    "            self.model.eval()\n",
    "            self.name = \"open_clip\"\n",
    "        except Exception:\n",
    "            from transformers import CLIPModel, CLIPProcessor\n",
    "            self.hf_model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14-336\").to(device)\n",
    "            self.hf_proc  = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14-336\")\n",
    "            self.hf_model.eval()\n",
    "            self.name = \"hf_clip\"\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def embed_images(self, files: List[str], batch=64) -> torch.Tensor:\n",
    "        feats = []\n",
    "        if self.name == \"open_clip\":\n",
    "            for i in tqdm(range(0, len(files), batch), desc=\"embed images (open_clip)\"):\n",
    "                imgs = []\n",
    "                for p in files[i:i+batch]:\n",
    "                    try: imgs.append(self.preprocess(Image.open(p).convert(\"RGB\")))\n",
    "                    except: continue\n",
    "                if not imgs: continue\n",
    "                ims = torch.stack(imgs).to(self.device)\n",
    "                f = self.model.encode_image(ims)\n",
    "                feats.append(F.normalize(f.float(), dim=-1))\n",
    "        else:\n",
    "            for i in tqdm(range(0, len(files), batch), desc=\"embed images (hf_clip)\"):\n",
    "                imgs = []\n",
    "                for p in files[i:i+batch]:\n",
    "                    try: imgs.append(Image.open(p).convert(\"RGB\"))\n",
    "                    except: continue\n",
    "                if not imgs: continue\n",
    "                inputs = self.hf_proc(images=imgs, return_tensors=\"pt\").to(self.device)\n",
    "                f = self.hf_model.get_image_features(**inputs)\n",
    "                feats.append(F.normalize(f.float(), dim=-1))\n",
    "        if not feats:\n",
    "            raise ValueError(\"No image features computed.\")\n",
    "        return torch.cat(feats, dim=0)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def embed_texts(self, texts: List[str], batch=256) -> torch.Tensor:\n",
    "        feats = []\n",
    "        if self.name == \"open_clip\":\n",
    "            tok = self.tokenizer\n",
    "            for i in tqdm(range(0, len(texts), batch), desc=\"embed texts (open_clip)\"):\n",
    "                t = tok(texts[i:i+batch]).to(self.device)\n",
    "                f = self.model.encode_text(t)\n",
    "                feats.append(F.normalize(f.float(), dim=-1))\n",
    "        else:\n",
    "            from transformers import CLIPProcessor  # already imported in __init__\n",
    "            for i in tqdm(range(0, len(texts), batch), desc=\"embed texts (hf_clip)\"):\n",
    "                inputs = self.hf_proc(text=texts[i:i+batch], return_tensors=\"pt\", padding=True, truncation=True).to(self.device)\n",
    "                f = self.hf_model.get_text_features(**inputs)\n",
    "                feats.append(F.normalize(f.float(), dim=-1))\n",
    "        return torch.cat(feats, dim=0)\n",
    "\n",
    "# --------- general helpers -----------------------------------------------------\n",
    "def _abs(p): return os.path.abspath(os.path.expanduser(p))\n",
    "def list_images_recursive(root, exts=(\".png\",\".jpg\",\".jpeg\",\".bmp\",\".webp\")) -> List[str]:\n",
    "    root = _abs(root)\n",
    "    return [p for p in glob.iglob(os.path.join(root, \"**\", \"*\"), recursive=True)\n",
    "            if os.path.isfile(p) and p.lower().endswith(exts)]\n",
    "\n",
    "def natural_key(path: str):\n",
    "    import re\n",
    "    b = os.path.basename(path)\n",
    "    return [int(t) if t.isdigit() else t.lower() for t in re.split(r\"(\\d+)\", b)]\n",
    "\n",
    "def flatten_to_tmp(files: List[str], tag: str) -> str:\n",
    "    out = pathlib.Path(tempfile.mkdtemp(prefix=f\"fid_flat_{tag}_\")).resolve()\n",
    "    for i, src in enumerate(files):\n",
    "        ext = pathlib.Path(src).suffix.lower() or \".png\"\n",
    "        dst = out / f\"{i:08d}{ext}\"\n",
    "        try: os.symlink(_abs(src), dst)\n",
    "        except Exception: shutil.copy2(_abs(src), dst)\n",
    "    return str(out)\n",
    "\n",
    "# --------- COCO caption mapping + per-folder prompts --------------------------\n",
    "def load_coco_maps(coco_json: str) -> Tuple[Dict[int,str], Dict[int,str]]:\n",
    "    with open(_abs(coco_json), \"r\", encoding=\"utf-8\") as f:\n",
    "        coco = json.load(f)\n",
    "    id2fname = {im[\"id\"]: im[\"file_name\"] for im in coco[\"images\"]}\n",
    "    id2cap: Dict[int,str] = {}\n",
    "    for ann in coco[\"annotations\"]:\n",
    "        id2cap.setdefault(ann[\"image_id\"], ann[\"caption\"].strip())  # first caption per image\n",
    "    return id2fname, id2cap\n",
    "\n",
    "def extract_coco_id_from_name(name: str):\n",
    "    m = re.search(r\"(?<!\\d)(\\d{12})(?!\\d)\", name)\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "def build_prompts_for_folder(gen_dir: str, id2fname: Dict[int,str], id2cap: Dict[int,str],\n",
    "                             out_txt: str, out_csv: str) -> List[str]:\n",
    "    files = sorted(list_images_recursive(gen_dir), key=natural_key)\n",
    "    prompts, rows = [], []\n",
    "    matched = 0\n",
    "    for p in files:\n",
    "        base = os.path.basename(p)\n",
    "        iid = extract_coco_id_from_name(base)\n",
    "        if iid is not None and iid in id2cap:\n",
    "            cap = id2cap[iid]\n",
    "            matched += 1\n",
    "            rows.append({\"filename\": base, \"image_id\": iid, \"coco_file_name\": id2fname.get(iid,\"\"),\n",
    "                         \"prompt\": cap, \"match_method\": \"12digit\"})\n",
    "        else:\n",
    "            cap = \"a photo\"  # fallback placeholder\n",
    "            rows.append({\"filename\": base, \"image_id\": \"\", \"coco_file_name\": \"\",\n",
    "                         \"prompt\": cap, \"match_method\": \"UNMATCHED\"})\n",
    "        prompts.append(cap)\n",
    "    with open(_abs(out_txt), \"w\", encoding=\"utf-8\") as f: f.write(\"\\n\".join(prompts))\n",
    "    with open(_abs(out_csv), \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        w = csv.DictWriter(f, fieldnames=[\"filename\",\"image_id\",\"coco_file_name\",\"prompt\",\"match_method\"])\n",
    "        w.writeheader(); w.writerows(rows)\n",
    "    print(f\"{gen_dir}: matched {matched}/{len(files)} to COCO captions -> {out_txt} (and {out_csv})\")\n",
    "    return prompts, files\n",
    "\n",
    "# --------- Metrics -------------------------------------------------------------\n",
    "def clip_and_ri1(files: List[str], prompts: List[str], backend: ClipBackend) -> Tuple[float, float]:\n",
    "    files_sorted = [f for _, f in sorted(zip([natural_key(x) for x in files], files))]\n",
    "    if len(files_sorted) != len(prompts):\n",
    "        raise ValueError(f\"Images ({len(files_sorted)}) vs prompts ({len(prompts)}) mismatch.\")\n",
    "    img_feat = backend.embed_images(files_sorted)\n",
    "    txt_feat = backend.embed_texts(prompts)\n",
    "    S = txt_feat @ img_feat.T\n",
    "    diag = torch.diag(S)\n",
    "    clip_mean = (torch.clamp(diag, min=0.0) * 2.5).mean().item()\n",
    "    top1 = S.argmax(dim=1)\n",
    "    ri1 = (top1 == torch.arange(S.size(0), device=top1.device)).float().mean().item()\n",
    "    return clip_mean, ri1\n",
    "\n",
    "def fid_folder_vs_folder(real_files: List[str], gen_files: List[str], tag: str) -> float:\n",
    "    flat_real = flatten_to_tmp(real_files, f\"real_{tag}\")\n",
    "    flat_gen  = flatten_to_tmp(gen_files,  f\"gen_{tag}\")\n",
    "    score = fid.compute_fid(flat_real, flat_gen, mode=\"clean\", num_workers=0, verbose=True)\n",
    "    print(f\"[{tag}] temp real dir: {flat_real}\\n[{tag}] temp gen  dir: {flat_gen}\")\n",
    "    return score\n",
    "\n",
    "# --------- RUN ----------------------------------------------------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# Gather image lists\n",
    "real_files = sorted(list_images_recursive(REAL_DIR), key=natural_key)\n",
    "fp16_files = sorted(list_images_recursive(FP16_DIR), key=natural_key)\n",
    "mixd_files = sorted(list_images_recursive(MIXDQ_DIR), key=natural_key)\n",
    "print(f\"Found files  real={len(real_files)} | fp16={len(fp16_files)} | mixdq={len(mixd_files)}\")\n",
    "if len(real_files) == 0 or len(fp16_files) == 0 or len(mixd_files) == 0:\n",
    "    raise FileNotFoundError(\"One of the folders has 0 readable images. Use ABSOLUTE paths; nested trees are OK.\")\n",
    "\n",
    "# Build per-folder prompts\n",
    "id2fname, id2cap = load_coco_maps(COCO_JSON)\n",
    "prompts_fp16, fp16_files = build_prompts_for_folder(FP16_DIR, id2fname, id2cap, OUT_FP16_TXT, OUT_FP16_CSV)\n",
    "prompts_mixd, mixd_files = build_prompts_for_folder(MIXDQ_DIR, id2fname, id2cap, OUT_MIXD_TXT, OUT_MIXD_CSV)\n",
    "\n",
    "# CLIP + RI@1\n",
    "backend = ClipBackend(device=device)\n",
    "print(\"CLIP backend:\", backend.name)\n",
    "clip_fp16, ri1_fp16 = clip_and_ri1(fp16_files, prompts_fp16, backend)\n",
    "clip_mixd, ri1_mixd = clip_and_ri1(mixd_files, prompts_mixd, backend)\n",
    "\n",
    "# FID\n",
    "fid_fp16  = fid_folder_vs_folder(real_files, fp16_files, tag=\"FP16\")\n",
    "fid_mixdq = fid_folder_vs_folder(real_files, mixd_files,  tag=\"MixDQ\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n=== SUMMARY (1024 subset) ===\")\n",
    "print(f\"CLIPScore (mean)  FP16:  {clip_fp16:.4f}    MixDQ: {clip_mixd:.4f}\")\n",
    "print(f\"RI@1              FP16:  {ri1_fp16*100:5.2f}%  MixDQ: {ri1_mixd*100:5.2f}%\")\n",
    "print(f\"FID (clean)       FP16:  {fid_fp16:.4f}       MixDQ: {fid_mixdq:.4f}\")\n",
    "# ==============================================================================\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
